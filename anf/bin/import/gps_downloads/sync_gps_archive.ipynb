{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to download data from Trimble GPS units and keep a local archive.\n",
    "\n",
    "The code will download raw T00 files and there is no conversion for now.\n",
    "\n",
    "\n",
    "     The algorithm is the following:\n",
    "       input ftp site\n",
    "       creates daily directories for raw and rinex files in top_folder\n",
    "       retrieves RINEX T00 trimble native format file\n",
    "       deletes the intermediate trimble dat files\n",
    "       \n",
    "       \n",
    "       MISSING:\n",
    "       converts trimble data files to RINEX files (.17o)\"\n",
    "       runs teqc to create a qc report (.17S)\"\n",
    "       hatanaka compresses then unix compresses the rinex .17o files\"\n",
    "       \n",
    "        Dependencies on other functions:\"\n",
    "          teqc\"\n",
    "          runpkr00\"\n",
    "          doy\"\n",
    "   \n",
    "Info: 172.16.153.231 .  ----- previous SIO test\" \n",
    "Info: 139.78.120.60 . ----- current okstate IP address\" \n",
    "Info: 139.78.120.60 /ags/data/seismogps/2017.234_ok 2017-08-22 \"\n",
    "\n",
    "EXAMPLE:\n",
    "\n",
    "        sync_gps_archive.py -v --maxfiles=2 --user=anonymous --password='jhaase@ucsd.edu' 139.78.120.60 ~/repos/temp\n",
    "\n",
    "HELP:\n",
    "\n",
    "        hurricane{reyes}% ./sync_gps_archive.py -h\n",
    "        usage: sync_gps_archive.py [-h] [-v] [-d] [--demo] [--delete] [--user USER]\n",
    "                                   [--password PASSWORD] [--maxattempts MAXATTEMPTS]\n",
    "                                   [--maxfiles MAXFILES] [--maxbytes MAXBYTES]\n",
    "                                   [--filter FILTER] [--agelimit AGELIMIT]\n",
    "                                   [--datelimit DATELIMIT]\n",
    "                                   ftpServer archive\n",
    "\n",
    "        Description: FTP into gps receiver, get raw datafiles The algorithm is the\n",
    "        following: input ftp site creates daily directories for raw files program\n",
    "        should run automatically once a day using crontab\n",
    "\n",
    "        positional arguments:\n",
    "          ftpServer             FTP server\n",
    "          archive               Local archive\n",
    "\n",
    "        optional arguments:\n",
    "          -h, --help            show this help message and exit\n",
    "          -v, --verbose         Run in verbose mode.\n",
    "          -d, --debug           Run FTP connection in debug mode.\n",
    "          --demo                DEMO or NULL run. Just show corrections.\n",
    "          --delete              Set if you want to clean out the remote directory.\n",
    "          --user USER           FTP username.\n",
    "          --password PASSWORD   FTP password.\n",
    "          --maxattempts MAXATTEMPTS\n",
    "                                Limit the amount of times to retry a single file.\n",
    "          --maxfiles MAXFILES   Limit the amount of files to downlaod.\n",
    "          --maxbytes MAXBYTES   Limit the amount of bytes to downlaod.\n",
    "          --filter FILTER       Filter for data files. Default to '.*T00'\n",
    "          --agelimit AGELIMIT   Avoid older than a set timewindow. ie. '6months',\n",
    "                                \"4weeks\" or \"60days\"\n",
    "          --datelimit DATELIMIT\n",
    "                                Only files after this date. ie. \"2017/11/03\"\n",
    "\n",
    "\n",
    "\n",
    "Juan Reyes reyes@ucsd.edu\n",
    "11/21/2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, re\n",
    "import glob\n",
    "from datetime import datetime,timedelta\n",
    "import collections\n",
    "import argparse\n",
    "try:\n",
    "    set\n",
    "except NameError:\n",
    "    from sets import Set as set\n",
    "\n",
    "from ftplib import FTP\n",
    "\n",
    "verboseFlag = False\n",
    "debugFlag = False\n",
    "\n",
    "'''\n",
    "If we are running in Jupyter Notebook then fake command line arguments.\n",
    "Run this if the module is running in IPython kernel,\n",
    "'''\n",
    "if  'ipykernel' in sys.modules:\n",
    "    args = ['sync_gps_archive', '--agelimit=1weeks', '--maxfiles=6',\n",
    "            '--maxattempts=2', '--user=anonymous','--password=jhaase@ucsd.edu',\n",
    "            '--datelimit=2017/11/18',\n",
    "            '139.78.120.60', '/notebooks/temp']\n",
    "else:\n",
    "    args = sys.argv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Set some generic print functions\n",
    "'''\n",
    "def notify( msg ):\n",
    "    print '%s: %s' % (datetime.now().strftime('%D %H:%M:%S.%f'), msg) \n",
    "    \n",
    "def log( msg ):\n",
    "    if verboseFlag:\n",
    "        notify( msg )\n",
    "        \n",
    "def debug( msg ):\n",
    "    if debugFlag:\n",
    "        notify( msg )\n",
    "        \n",
    "def error( msg ):\n",
    "    print '%s: ERROR' % datetime.now().strftime('%D %H:%M:%S.%f')\n",
    "    notify( msg )\n",
    "    print '%s: EXIT' % datetime.now().strftime('%D %H:%M:%S.%f')\n",
    "    if __name__ == '__main__':\n",
    "        sys.exit()\n",
    "    else:\n",
    "        raise Exception( msg )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parse command line arguments. Save\n",
    "values to variable \"args\".\n",
    "'''\n",
    "\n",
    "helpString = '''\n",
    "Description:\n",
    "    FTP into gps receiver, get raw datafiles\n",
    "    \n",
    "    The algorithm is the following:\n",
    "       input ftp site\n",
    "       creates daily directories for raw files\n",
    "       program should run automatically once a day using crontab\n",
    "       \n",
    "'''\n",
    "parser = argparse.ArgumentParser(description=helpString)\n",
    "\n",
    "parser.add_argument('-v', '--verbose', action='store_true', dest='verbose',\n",
    "                                    default=False, help='Run in verbose mode.')\n",
    "\n",
    "parser.add_argument('-d', '--debug', action='store_true', dest='debug',\n",
    "                                    default=False, help='Run FTP connection in debug mode.')\n",
    "\n",
    "parser.add_argument('--demo', action='store_true', dest='demo', default=False,\n",
    "                                    help='DEMO or NULL run. Just show corrections.')\n",
    "\n",
    "parser.add_argument('--delete', action='store_true', dest='delete', default=False,\n",
    "                                    help='Set if you want to clean out the remote directory.')\n",
    "\n",
    "parser.add_argument('--user', action='store', dest='user', default=None,\n",
    "                                    help='FTP username.')\n",
    "\n",
    "parser.add_argument('--password', action='store', dest='password', default=None,\n",
    "                                    help='FTP password.')\n",
    "\n",
    "parser.add_argument('--maxattempts', action='store', dest='maxAttempts', default=None, type=int,\n",
    "                                    help='Limit the amount of times to retry a single file.')\n",
    "\n",
    "parser.add_argument('--maxfiles', action='store', dest='maxFiles', default=None, type=int,\n",
    "                                    help='Limit the amount of files to downlaod.')\n",
    "\n",
    "parser.add_argument('--maxbytes', action='store', dest='maxBytes', default=None, type=int,\n",
    "                                    help='Limit the amount of bytes to downlaod.')\n",
    "\n",
    "parser.add_argument('--filter', action='store', dest='filter', default=r'.*T00$',\n",
    "                                    help='Filter for data files. Default to \".*T00$\"')\n",
    "\n",
    "parser.add_argument('--agelimit', action='store', dest='agelimit', default=None,\n",
    "                                    help='Avoid older than a set timewindow. ie. \"1month\", \"4weeks\" or \"60days\"')\n",
    "\n",
    "parser.add_argument('--datelimit', action='store', dest='datelimit', default=None,\n",
    "                                    help='Only files after this date. ie. \"2017/11/03\"')\n",
    "\n",
    "# positional arguments\n",
    "parser.add_argument('ftpServer', type=str, help='FTP server')\n",
    "\n",
    "parser.add_argument('archive', type=str, help='Local archive')\n",
    "\n",
    "config = parser.parse_args( args[1:] )\n",
    "args_dict = vars( config )\n",
    "\n",
    "\n",
    "if not config.ftpServer or not config.archive:\n",
    "    parser.print_help()\n",
    "    exit(-1)\n",
    "    \n",
    "if (config.verbose):\n",
    "    verboseFlag = config.verbose\n",
    "    \n",
    "if (config.debug):\n",
    "    verboseFlag = config.debug\n",
    "    debugFlag = config.debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/22/17 02:52:03.441081: sync_gps_archive --agelimit=1weeks --maxfiles=6 --maxattempts=2 --user=anonymous --password=jhaase@ucsd.edu --datelimit=2017/11/18 139.78.120.60 /notebooks/temp\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Nice print of command-line options \n",
    "'''\n",
    "notify( (' ').join(args) )\n",
    "for x in args_dict:\n",
    "    log( '\\t%s: %s' % (x.upper(), args_dict[x]) )\n",
    "    \n",
    "\n",
    "'''\n",
    "Verify local archive\n",
    "'''\n",
    "if not os.path.exists( config.archive ):\n",
    "    log( 'Making new directory: [%s]' % config.archive )\n",
    "    \n",
    "    try:\n",
    "        os.makedirs( config.archive )\n",
    "    except Exception,e:\n",
    "        error('Cannot create archive folder [%s] %s:%s' % \\\n",
    "              ( config.archive, Exception,e))\n",
    "\n",
    "try:\n",
    "    os.stat( config.archive )\n",
    "except Exception,e:\n",
    "    error('Cannot create archive folder [%s] %s:%s' % \\\n",
    "          ( config.archive, Exception,e))\n",
    "    \n",
    "log( 'Working on archive: [%s]' % config.archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makePath( path, cache ):\n",
    "    '''\n",
    "    makePath:\n",
    "    \n",
    "    Traverse the dictionary structure and build full paths.\n",
    "    Since each key is a portion of the path until the last\n",
    "    key with a NULL value. That is the filename.\n",
    "    '''\n",
    "    \n",
    "    pathList = []\n",
    "    \n",
    "    for k,v in cache.iteritems():\n",
    "        \n",
    "        if not v:\n",
    "            pathList.append( '%s/%s' % (path,k) )\n",
    "        else:\n",
    "            pathList += makePath( '%s/%s' % (path,k), v )\n",
    "            \n",
    "    return pathList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsetFiles( fileList ):\n",
    "    '''\n",
    "    subsetFiles:\n",
    "    \n",
    "    From all files found filter the ones that\n",
    "    match the config.filter regex.\n",
    "    \n",
    "    '''\n",
    "    log( 'Make full paths of each file' )\n",
    "    \n",
    "    log( 'Total files [%s]' % len(fileList) )\n",
    "\n",
    "    if config.filter:\n",
    "        log( 'Make regex filter for files [%s]' % config.filter )\n",
    "        regex = re.compile( config.filter )\n",
    "\n",
    "        fileList = filter(regex.search, fileList)\n",
    "        log( 'Total files after subset[%s]' % len(fileList) )\n",
    "\n",
    "    log( 'Final file list' )\n",
    "    log( fileList ) \n",
    "    \n",
    "    return fileList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse( ftp ):\n",
    "    \"\"\"\n",
    "    traverse:\n",
    "    \n",
    "    return a recursive listing of an ftp server contents\n",
    "\n",
    "    listing is returned as a recursive dictionary, where each key\n",
    "    contains a contents of the subdirectory or None if it corresponds\n",
    "    to a file.\n",
    "    \"\"\"\n",
    "    level = {}\n",
    "    dirList = []\n",
    "    ftp.dir(dirList.append)\n",
    "    \n",
    "    for each in (path for path in dirList[1:] if path not in ('.', '..')):\n",
    "        #log( 'traverse: [%s]' % each )\n",
    "        name = each.strip().split(' ')[-1]\n",
    "        #'drwxrwxrwx  11 5000     5000         4096 Nov 20 23:54 201711'\n",
    "        \n",
    "        try:\n",
    "            ftp.cwd( name )\n",
    "            level[name] = traverse( ftp )\n",
    "            ftp.cwd( '..' )\n",
    "        except:\n",
    "            level[name] = None\n",
    "    return level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverseLocal( folder ):\n",
    "    '''\n",
    "    traverseLocal:\n",
    "    \n",
    "    return a recursive listing of a directory structure\n",
    "\n",
    "    listing is returned as a recursive dictionary, where each key\n",
    "    contains a contents of the subdirectory or None if it corresponds\n",
    "    to a file.\n",
    "    '''\n",
    "    level = {}\n",
    "    \n",
    "    dirList = []\n",
    "    \n",
    "    #log( 'Traverse Local Folder: [%s]' % folder )\n",
    "    \n",
    "    #cwd = os.getcwd()\n",
    "    #os.chdir( folder )\n",
    "    \n",
    "    #for each in (path for path in  os.listdir('.') if path not in ('.', '..')):\n",
    "    for each in (path for path in  os.listdir( folder ) if path not in ('.', '..')):\n",
    "        fullname = '%s/%s' % (folder, each)\n",
    "        #log( 'traverse: [%s]' % fullname )\n",
    "        \n",
    "        if os.path.isfile( fullname ):\n",
    "            level[each] = None\n",
    "        else:\n",
    "            level[each] = traverseLocal( fullname )\n",
    "\n",
    "    #os.chdir( cwd )\n",
    "    \n",
    "    return level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileDate( filename ):\n",
    "    '''\n",
    "    fileDate:\n",
    "    \n",
    "    Parse file name into file date object\n",
    "        # EXAMPLE:    KERG201711172100a.T00\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        m = re.search( r'^.*(\\d{4})(\\d{2})(\\d{2})(\\d{2})(\\d{2}).*$', filename)\n",
    "        #log( 'regex: %s/%s/%s %s:%s' % (m.group(1),m.group(2),m.group(3),m.group(4),m.group(5)) )\n",
    "        testdate = datetime( int(m.group(1)), int(m.group(2)), int(m.group(3)), int(m.group(4)), int(m.group(5)) )\n",
    "    except Exception, e:\n",
    "        log( '%s: %s' % (Exception,e) )\n",
    "        yr = int( filename[4:8] )\n",
    "        mt = int( filename[8:10] )\n",
    "        dy = int( filename[10:12] )\n",
    "        hr = int( filename[12:14] )\n",
    "        mn = int( filename[14:16] )\n",
    "        #log( 'simple: %s/%s/%s %s:%s' % (yr,mt,dy,hr,mn) )\n",
    "        testdate = datetime( yr, mt, dy, hr, mn )\n",
    "        \n",
    "    if testdate < datetime(2000, 1, 1) or datetime(2100, 1, 1)< testdate:\n",
    "        notify( '%s' % filename )\n",
    "        error( 'Date is not valid in filename!!!' )\n",
    "        \n",
    "    log( '\\tNew time: %s' % testdate )\n",
    "    \n",
    "    return testdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateLimit( conf ):\n",
    "    '''\n",
    "    dateLimit:\n",
    "    \n",
    "    Calculate date limit of files that we want to\n",
    "    download. Based on command-line flags.\n",
    "        - age limit: No more than X weeks or Y months\n",
    "        - date limit: Not older than day X\n",
    "    '''\n",
    "    \n",
    "    now = datetime.now()\n",
    "    \n",
    "    limit = datetime( 2000, 1, 1 )\n",
    "    \n",
    "    # maybe we have a timewindow\n",
    "    if conf.agelimit:\n",
    "        \n",
    "        log( 'Parse age limit of files [%s]' % conf.agelimit )\n",
    "        try:\n",
    "            m = re.search( r'^(\\d+)(\\w+)$', conf.agelimit)\n",
    "            digit = int( m.group(1) )\n",
    "            string = m.group(2)\n",
    "            log( 'Limit to %s %s' % (digit, string) )\n",
    "            \n",
    "            if re.match( r'month.?', string ):\n",
    "                m, y = (now.month+digit) % 12, now.year + ((now.month)+digit-1) // 12\n",
    "                if not m: m = 12\n",
    "                d = min(now.day, [31,\n",
    "                    29 if y%4==0 and not y%400==0 else 28,31,30,31,30,31,31,30,31,30,31][m-1])\n",
    "                limit = now.replace(day=d,month=m, year=y)\n",
    "            elif re.match( r'week.?', string ):\n",
    "                limit = now - timedelta( weeks=digit )\n",
    "            elif re.match( r'day.?', string ):\n",
    "                limit = now - timedelta( days=digit )\n",
    "            else:\n",
    "                error( 'Cannot parse age limit string: [%s]' % string)\n",
    "                \n",
    "        except Exception,e:\n",
    "            error( 'Problem parsing age limit %s %s' % (Exception, e) )\n",
    "            \n",
    "            \n",
    "    # maybe we have a date limit\n",
    "    if conf.datelimit:\n",
    "        \n",
    "        log( 'Parse date limit of files [%s]' % conf.datelimit )\n",
    "        dateparts = conf.datelimit.split('/')\n",
    "        \n",
    "        try:\n",
    "            log( 'date limit: %s/%s/%s' % (dateparts[0],dateparts[1],dateparts[2]) )\n",
    "            limit = datetime( int(dateparts[0]), int(dateparts[1]), int(dateparts[2]) )\n",
    "        except Exception,e:\n",
    "            error( 'Problem parsing date limit %s %s' % (Exception, e) )\n",
    "            \n",
    "    if limit > datetime( 2000, 1, 1 ):\n",
    "        log( 'Limit on age of files found to be: %s' % limit )\n",
    "    else:\n",
    "        log( 'No limit on age of files')\n",
    "        \n",
    "    return limit\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trashFile( filename ):\n",
    "    '''\n",
    "    trashFile:\n",
    "    \n",
    "    Move file to trash mode.\n",
    "    In case of partial download then move to the side and\n",
    "    append _trash_# for each extra version.\n",
    "    '''\n",
    "    notify( 'Move file to trash structure: %s' % filename )\n",
    "    \n",
    "    otherFiles = glob.glob( filename + '*' )\n",
    "    \n",
    "    if len(otherFiles):\n",
    "        notify( 'Found %s other files for it.' % len(otherFiles) )\n",
    "        for each in otherFiles:\n",
    "            notify( '\\t%s %s bytes' % (each,os.path.getsize(each)) )\n",
    "    else:\n",
    "        notify( 'No other trahs files for it.' )\n",
    "        \n",
    "    newName = filename + '_trash_' + str(len(otherFiles))\n",
    "    try:\n",
    "        os.rename( filename, newName )\n",
    "    except Exception,e:\n",
    "        error( 'Cannot move %s to %s trash structure: %s %s' % (filename, newName, Exception,e) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadFTP( ftp, remoteFile, localFile, delete=False ):\n",
    "    '''\n",
    "    downloadFTP:\n",
    "    \n",
    "    Download file from FTP server.\n",
    "        - Verify if we have directory ready\n",
    "        - Download the file\n",
    "        - Verify final size of local file\n",
    "        - Move to \"trash\" mode if different size\n",
    "        - Remove remote if needed\n",
    "    '''\n",
    "    \n",
    "    (localDir, localName)= os.path.split(localFile)\n",
    "    success = False\n",
    "    totalFiles = 0\n",
    "    totalDeleted = 0\n",
    "    \n",
    "    # Verify local archive\n",
    "    log( '\\tOpen pointer to local file: %s' % localFile )\n",
    "    try:\n",
    "        if not os.path.isdir( localDir ):\n",
    "            os.makedirs( localDir )\n",
    "        fileObj = open(localFile, 'wb')\n",
    "    except Exception,e:\n",
    "        error( '\\tProblem creating new file: %s %s' % (Exception,e))\n",
    "        \n",
    "    # Download the file a chunk at a time using RETR\n",
    "    ftp.retrbinary('RETR ' + remoteFile, fileObj.write)\n",
    "    \n",
    "    # Close the file\n",
    "    fileObj.close()\n",
    "    \n",
    "    fileSize = ftp.size( remoteFile )\n",
    "    log( '\\tFile size: %s bytes' % fileSize )\n",
    "    \n",
    "    localFileSize = os.path.getsize(localFile)\n",
    "    log( '\\tLocal File: %s bytes' % localFileSize )\n",
    "    \n",
    "    if localFileSize == fileSize:\n",
    "        log( '\\tSuccess in download of file.')\n",
    "        notify( 'Downloaded: %s' % localName )\n",
    "        success = True\n",
    "        totalFiles += 1\n",
    "    else:\n",
    "        notify( 'ERROR in download. Remove local file.')\n",
    "        notify( 'remote:[%s bytes] local:[%s bytes]' % (fileSize, localFileSize) )\n",
    "        try:\n",
    "            trashFile( localFile )\n",
    "        except Exception,e:\n",
    "            error( '\\tCannot remove partial local file: %s [%s:%s]' % \\\n",
    "                  (localFile, Exception, e) )\n",
    "\n",
    "    if delete:\n",
    "        notify( 'Delete remote file:%s' % remoteFile )\n",
    "        ftp.delete( remoteFile )\n",
    "        totalDeleted += 1\n",
    "            \n",
    "            \n",
    "    return {\n",
    "        'success': success,\n",
    "        'size':localFileSize,\n",
    "        'localDir':localDir,\n",
    "        'localName':localName,\n",
    "        'totalFiles':totalFiles,\n",
    "        'totalDeleted':totalDeleted,\n",
    "        'downloaded':fileSize\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syncFTP( conf ):\n",
    "    '''\n",
    "    syncFTP: Coordinate the download of the files:\n",
    "    \n",
    "    - Read the remote folder\n",
    "    - Read the local folder\n",
    "    - Compile list of missing files\n",
    "    - Connect to an FTP server and bring down files to the local directory\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        notify( 'Connect to %s' % conf.ftpServer )\n",
    "        ftpSite = FTP( conf.ftpServer )\n",
    "        \n",
    "        #if conf.verbose:\n",
    "        #    ftpSite.set_debuglevel( 1 )\n",
    "            \n",
    "        if conf.debug:\n",
    "            ftpSite.set_debuglevel( 2 )\n",
    "            \n",
    "    except:\n",
    "        error( 'Cannot find server %s' % conf.ftpServer )\n",
    "        \n",
    "    notify( 'Connecting...' )\n",
    "    if conf.user and conf.password:\n",
    "        log( 'login( %s, %s )' % (conf.user,conf.password) )\n",
    "        ftpSite.login(conf.user,conf.password)\n",
    "    else:\n",
    "        ftpSite.login()\n",
    "        \n",
    "    ftpSite.cwd( '/' )\n",
    "    \n",
    "    \n",
    "    notify( 'Read remote folder structure...' )\n",
    "    \n",
    "    try:\n",
    "        remoteFiles = subsetFiles( makePath( '', traverse( ftpSite ) ) )\n",
    "    except:\n",
    "        error( 'Remote directory listing ERROR - ' )\n",
    "    \n",
    "    localFiles = subsetFiles( makePath( '', traverseLocal( conf.archive ) ) )\n",
    "    \n",
    "    transferList = list(set(remoteFiles) - set(localFiles))\n",
    "    notify( 'Missing %s files' % len(transferList) )\n",
    "    \n",
    "    try:\n",
    "        filesMoved = 0\n",
    "        totalBytes = 0\n",
    "        totalFiles = []\n",
    "        totalMissed = []\n",
    "        dateFileLimit = dateLimit( conf ) \n",
    "        \n",
    "        for fl in sorted(transferList, reverse=False):\n",
    "            \n",
    "            fileDateObject = fileDate( fl )\n",
    "            log( 'File: %s Date: %s' % (fl, fileDateObject) )\n",
    "            \n",
    "            if fileDateObject < dateFileLimit:\n",
    "                log( '\\tFile too old. Skip.')\n",
    "                continue\n",
    "                \n",
    "            localFile =  os.path.abspath('%s/%s' % (conf.archive, fl) )\n",
    "            \n",
    "            if conf.maxAttempts:\n",
    "                otherFiles = glob.glob( localFile + '*' )\n",
    "                \n",
    "                if len(otherFiles) >= 1:\n",
    "                    log( '\\tAlready have %s attempts to this file' % len(otherFiles) )\n",
    "                    for each in otherFiles:\n",
    "                        modified = datetime.fromtimestamp(os.path.getmtime(each))\n",
    "                        log( '\\t%s %s bytes on %s' % (each,os.path.getsize(each),modified) )\n",
    "                \n",
    "                if len(otherFiles) >= conf.maxAttempts:\n",
    "                    notify( '\\tSkip. Max attempts on: %s' % len(otherFiles) )\n",
    "                    log( '\\t%s' % (otherFiles) )\n",
    "                    continue\n",
    "            \n",
    "            log( '\\tStart work on: %s' % fl )\n",
    "            \n",
    "            if conf.demo:\n",
    "                log( '\\tDEMO RUN. Skip' )\n",
    "                continue\n",
    "              \n",
    "            \n",
    "            results = downloadFTP( ftpSite, fl, localFile, conf.delete )\n",
    "            #{\n",
    "            #    'success': success,\n",
    "            #    'size':localFileSize,\n",
    "            #    'localDir':localDir,\n",
    "            #    'localName':localName,\n",
    "            #    'totalFiles':totalFiles,\n",
    "            #    'totalDeleted':totalDeleted,\n",
    "            #    'downloaded':fileSize\n",
    "            #}\n",
    "            \n",
    "            if results['success']:\n",
    "                totalFiles.append( results['localName'] )\n",
    "                filesMoved += results['totalFiles']\n",
    "            else:\n",
    "                totalMissed.append( results['localName'] )\n",
    "                \n",
    "            totalBytes += results['downloaded']\n",
    "            \n",
    "            if conf.maxFiles:\n",
    "                log( '\\t%s/%s max files allowed' % (filesMoved,conf.maxFiles) )\n",
    "                if filesMoved >= conf.maxFiles:\n",
    "                    notify( '\\tGot to limit on total files: %s' % conf.maxFiles )\n",
    "                    break\n",
    "                    \n",
    "            if conf.maxBytes:\n",
    "                log( '\\t%s/%s max bytes allowed' % (totalBytes,conf.maxBytes) )\n",
    "                if totalBytes >= conf.maxBytes:\n",
    "                    notify( '\\tGot to limit on total bytes: %s' % conf.maxBytes )\n",
    "                    break\n",
    "            \n",
    "        notify( 'Downloaded %s Files with %s bytes' %  (filesMoved, totalBytes) )\n",
    "        for each in totalFiles:\n",
    "            log( 'Downloaded: %s' % each )\n",
    "        \n",
    "        if len( totalMissed ):\n",
    "            notify( 'Error on %s files' %  totalMissed )\n",
    "            notify(  totalMissed )\n",
    "        else:\n",
    "            notify( 'No errors on any download.' )\n",
    "        \n",
    "    except Exception, e:\n",
    "        error( 'Download Error %s: %s' % ( Exception, e) )\n",
    "        \n",
    "    ftpSite.close() # Close FTP connection\n",
    "    ftpSite = None\n",
    "    \n",
    "    return len(totalMissed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/22/17 02:52:03.656168: Connect to 139.78.120.60\n",
      "11/22/17 02:52:07.135863: Connecting...\n",
      "11/22/17 02:52:07.850002: Read remote folder structure...\n",
      "11/22/17 02:52:29.272901: Missing 152 files\n",
      "11/22/17 02:52:34.712183: Downloaded: KERG201711191600a.T00\n",
      "11/22/17 02:52:40.491169: Downloaded: KERG201711191700a.T00\n",
      "11/22/17 02:52:45.577045: Downloaded: KERG201711191800a.T00\n",
      "11/22/17 02:52:50.422207: Downloaded: KERG201711191900a.T00\n",
      "11/22/17 02:52:55.379288: Downloaded: KERG201711192000a.T00\n",
      "11/22/17 02:53:00.889910: Downloaded: KERG201711192100a.T00\n",
      "11/22/17 02:53:00.890405: \tGot to limit on total files: 6\n",
      "11/22/17 02:53:00.890581: Downloaded 6 Files with 13792215 bytes\n",
      "11/22/17 02:53:00.890745: No errors on any download.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Start download of the data files\n",
    "'''\n",
    "log( 'Retreiving Files' )\n",
    "\n",
    "if 'ipykernel' in sys.modules:\n",
    "    # Run this if inside Jupyter Notebook\n",
    "    syncFTP(config)\n",
    "else:\n",
    "    sys.exit( syncFTP(config) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   # make files writeable by owner and group\n",
    "#   # chmod ug+w *\n",
    "#   echo 'converting .T00 files to .dat files'\n",
    "#   foreach f ($daily_raw/*.T00)\n",
    "#      runpkr00 -d $f\n",
    "#   end\n",
    "#   echo 'Converted .T00 files to .DAT files'\n",
    "#   \n",
    "#   \n",
    "#   # Making rinex files using teqc\n",
    "#   cd $daily_rinex\n",
    "#   foreach datfile ( $daily_raw/*.dat )\n",
    "#     set fname = `basename -s .dat $datfile`\n",
    "#     teqc ++err translate_${doy}.err -tr d $datfile > $fname.${yr}o \n",
    "#   end\n",
    "#   \n",
    "#   # qc data\n",
    "#   # get all 4 char site names from the list of files \n",
    "#   ls *.${yr}o | awk '{print substr($1,1,4)}' | sort | uniq > tmp_sitelist.txt\n",
    "#   foreach site (`cat tmp_sitelist.txt`)\n",
    "#     echo 'GPS DATA QC in progress'\n",
    "#     # teqc +qc *.${yr}o > $qcname.${yr}S\n",
    "#     teqc +qc $site*.${yr}o  > /dev/null\n",
    "#   end\n",
    "#   echo $daily_qc\n",
    "#   mv *.${yr}S $daily_qc\n",
    "#   mv translate_${doy}.err $daily_qc\n",
    "#   \n",
    "#   foreach rinex_file ( *.${yr}o )\n",
    "#     rnx2crx $rinex_file\n",
    "#     rm $rinex_file\n",
    "#   end\n",
    "#   compress *.${yr}d\n",
    "#   \n",
    "#   # Clean up \n",
    "#   rm tmp_sitelist.txt\n",
    "#   cd $daily_raw\n",
    "#   rm *.dat\n",
    "#   compress *.T00\n",
    "#   \n",
    "#   cd $current_dir\n",
    "#   \n",
    "#   echo \"get_gpsdata complete for $year $doy = $year-$month-$day\"\n",
    "#   # when using cron, may have to change the doy variable....depends on when cron job takes\n",
    "#   # place.\n",
    "#   # still need to find out about t02 to rinex....\n",
    "#   #  annnnnnd break..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
