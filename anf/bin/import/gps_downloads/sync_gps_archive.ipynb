{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYNC_GPS_ARCHIVE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to download data from Trimble GPS units and keep a local archive.\n",
    "\n",
    "The code will download raw T00 files and there is no conversion for now.\n",
    "   \n",
    "    Info: 172.16.153.231 - previous SIO test \n",
    "    Info: 139.78.120.60  - current okstate IP address\n",
    "    Info: 139.78.120.60  /ags/data/seismogps/2017.234_ok 2017-08-22\n",
    "\n",
    "EXAMPLE:\n",
    "\n",
    "        sync_gps_archive.py -v --maxfiles=2 139.78.120.60 ~/repos/temp\n",
    "\n",
    "Juan Reyes reyes@ucsd.edu\n",
    "11/21/2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, re\n",
    "import glob\n",
    "from datetime import datetime,timedelta\n",
    "import collections\n",
    "import argparse\n",
    "try:\n",
    "    set\n",
    "except NameError:\n",
    "    from sets import Set as set\n",
    "\n",
    "from ftplib import FTP\n",
    "\n",
    "verboseFlag = False\n",
    "debugFlag = False\n",
    "\n",
    "'''\n",
    "If we are running in Jupyter Notebook then fake command line arguments.\n",
    "Run this if the module is running in IPython kernel,\n",
    "'''\n",
    "if  'ipykernel' in sys.modules:\n",
    "    args = ['sync_gps_archive', '--agelimit=1weeks', '--maxfiles=6',\n",
    "            '--maxattempts=2', '--datelimit=2017/11/18','--blocksize=2500',\n",
    "            '139.78.120.60', '/notebooks/temp']\n",
    "else:\n",
    "    args = sys.argv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Set some generic print functions\n",
    "'''\n",
    "def notify( msg ):\n",
    "    print '%s: %s' % (datetime.now().strftime('%D %H:%M:%S.%f'), msg) \n",
    "    \n",
    "def log( msg ):\n",
    "    if verboseFlag:\n",
    "        notify( msg )\n",
    "        \n",
    "def debug( msg ):\n",
    "    if debugFlag:\n",
    "        notify( msg )\n",
    "        \n",
    "def error( msg ):\n",
    "    print '%s: ERROR' % datetime.now().strftime('%D %H:%M:%S.%f')\n",
    "    notify( msg )\n",
    "    print '%s: EXIT' % datetime.now().strftime('%D %H:%M:%S.%f')\n",
    "    if __name__ == '__main__':\n",
    "        sys.exit()\n",
    "    else:\n",
    "        raise Exception( msg )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parse command line arguments. Save values to variable \"args\".\n",
    "\n",
    "Configure HELP strings for script.\n",
    "You can make a manpage with this command:\n",
    "    help2man -o sync_gps_archive.1  --no-discard-stderr  sync_gps_archive\n",
    "    \n",
    "First run of \"make install\" will get all files into the system. Then we can\n",
    "run help2man to output the manpage.1 file. This will require a second\n",
    "pass of the \"make install\". \n",
    "\n",
    "'''\n",
    "\n",
    "description = '''\n",
    "\n",
    "Tool to keep Trimble FTP archive in sync to a local repo. Defaults to\n",
    "files ending in .T00 but you can change this in the flags. It will keep\n",
    "the directory structure encounter at the remote site. Files will problems\n",
    "will be appended with a string \"_trash_\" and a number. There is a default\n",
    "of 6 attempts per file. After this, the file will be ignored. You can also\n",
    "set the number of files to download on a single run or the maximum data\n",
    "that can be downloaded on a  single attempt.\n",
    "\n",
    "The list of files could be limited by a set date with a flag --datelimit\n",
    "and no files older than that date will be downloaded. The format is\n",
    "\"2017/12/31\".  There is  also a  time window limit if you only want to\n",
    "download files within a rolling time window from realtime. This is done\n",
    "with the flag --agelimit and the format is a number and a string from the\n",
    "list  [days, weeks,  months,  years](with or  without the  s at the end)\n",
    "without spaces. i.e. \"2weeks\" or \"90days\".\n",
    "\n",
    "There is a flag to remove files from the remote archive after a successful\n",
    "download to the local archive. This is verified by looking at the size of\n",
    "the local file and the reported size from the FTP server. All file size\n",
    "metrics are reported in bytes. The --maxbytes flag also uses bytes to limit\n",
    "the total bandwidth used for each run.\n",
    "\n",
    "'''\n",
    "\n",
    "epilog = '''\n",
    "PROCESS:\n",
    "    The algorithm is the following:\n",
    "        1. input ftp site\n",
    "\n",
    "        2. creates daily directories for raw and rinex files in top_folder\n",
    "\n",
    "        3. retrieves RINEX T00 trimble native format file\n",
    "\n",
    "        4. deletes the intermediate trimble dat files\n",
    "\n",
    "    Program should run automatically once a day using crontab\n",
    "    \n",
    "MISSING:\n",
    "    Converts trimble data files to RINEX files (.17o)\n",
    "    \n",
    "    Run teqc to create a qc report (.17S)\n",
    "    \n",
    "    Run hatanaka compresses then unix compresses the rinex .17o files\n",
    "    \n",
    "EXAMPLE:\n",
    "    sync_gps_archive -v --maxfiles=2 139.78.120.60 ~/repos/temp\n",
    "    \n",
    "HELP:\n",
    "    sync_gps_archive -h\n",
    "\n",
    "\n",
    "Report bugs to Juan Reyes <reyes@ucsd.edu>.\n",
    "'''\n",
    "\n",
    "version = '''\n",
    "%(prog)s 1.0\n",
    "\n",
    "Copyright (c) 2017, The Regents of the University of California\n",
    "All rights reserved.\n",
    "\n",
    "Redistribution and use in source and binary forms, with or without modification,\n",
    "are permitted provided that the following conditions are met:\n",
    " 1. Redistributions of source code must retain the above copyright notice, this\n",
    "    list of conditions and the following disclaimer.\n",
    " 2. Redistributions in binary form must reproduce the above copyright notice,\n",
    "    this list of conditions and the following disclaimer in the documentation and/or\n",
    "    other materials provided with the distribution.\n",
    "\n",
    "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\n",
    "ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n",
    "WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR\n",
    "ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n",
    "(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n",
    "LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\n",
    "ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n",
    "(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n",
    "SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "\n",
    "\n",
    "Written by Juan Reyes <reyes@ucsd.edu>\n",
    "'''\n",
    "parser = argparse.ArgumentParser( prog='sync_gps_archive',\n",
    "                    formatter_class=argparse.RawTextHelpFormatter,\n",
    "                    description=description, epilog=epilog)\n",
    "\n",
    "parser.add_argument('-V', '--version', action='version', version=version)\n",
    "\n",
    "parser.add_argument('-v', '--verbose', action='store_true', dest='verbose', default=False,\n",
    "                    help='Run in verbose mode.(default: %(default)s)')\n",
    "\n",
    "parser.add_argument('-d', '--debug', action='store_true', dest='debug', default=False,\n",
    "                    help='Run FTP connection in debug mode.(default: %(default)s)')\n",
    "\n",
    "parser.add_argument('--demo', action='store_true', dest='demo', default=False,\n",
    "                    help='DEMO or NULL run. Just show corrections.(default: %(default)s)')\n",
    "\n",
    "parser.add_argument('--delete', action='store_true', dest='delete', default=False,\n",
    "                    help='Set if you want to clean out the remote directory.(default: %(default)s)')\n",
    "\n",
    "parser.add_argument('--user', action='store', dest='user', default=None,\n",
    "                    help='FTP username.(default: %(default)s)')\n",
    "\n",
    "parser.add_argument('--password', action='store', dest='password', default=None,\n",
    "                    help='FTP password.(default: %(default)s)')\n",
    "\n",
    "parser.add_argument('--maxattempts', action='store', dest='maxAttempts', default=6, type=int,\n",
    "                    help='Limit the amount of times to retry a single file.(default: %(default)s)')\n",
    "\n",
    "parser.add_argument('--maxfiles', action='store', dest='maxFiles', default=None, type=int,\n",
    "                    help='Limit the amount of files to downlaod.(default: %(default)s)')\n",
    "\n",
    "parser.add_argument('--maxbytes', action='store', dest='maxBytes', default=None, type=int,\n",
    "                    help='Limit the amount of bytes to downlaod.(default: %(default)s)')\n",
    "\n",
    "parser.add_argument('--blocksize', action='store', dest='blocksize', default=8192, type=int,\n",
    "                    help='Maximum chunk size to read on the low-level FTP socket.(default: %(default)s)')\n",
    "\n",
    "parser.add_argument('--filter', action='store', dest='filter', default=r'.*T00$',\n",
    "                    help='Filter for data files. Default to \".*T00$\".(default: %(default)s)')\n",
    "\n",
    "parser.add_argument('--agelimit', action='store', dest='agelimit', default=None,\n",
    "                    help='Avoid older than a set timewindow. ie. \"1month\", \"4weeks\" or \"60days\".(default: %(default)s)')\n",
    "\n",
    "parser.add_argument('--datelimit', action='store', dest='datelimit', default=None,\n",
    "                    help='Only files after this date. ie. \"2017/11/03\". (default: %(default)s)')\n",
    "\n",
    "# positional arguments\n",
    "parser.add_argument('ftpServer', type=str, help='FTP server')\n",
    "\n",
    "parser.add_argument('archive', type=str, help='Local archive')\n",
    "\n",
    "\n",
    "'''\n",
    "Parse command line arguments. Save values to variable \"args\".\n",
    "'''\n",
    "config = parser.parse_args( args[1:] )\n",
    "args_dict = vars( config )\n",
    "\n",
    "\n",
    "if not config.ftpServer or not config.archive:\n",
    "    parser.print_help()\n",
    "    exit(-1)\n",
    "    \n",
    "if (config.verbose):\n",
    "    verboseFlag = config.verbose\n",
    "    \n",
    "if (config.debug):\n",
    "    verboseFlag = config.debug\n",
    "    debugFlag = config.debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/22/17 23:11:54.657815: sync_gps_archive --agelimit=1weeks --maxfiles=6 --maxattempts=2 --datelimit=2017/11/18 --blocksize=2500 139.78.120.60 /notebooks/temp\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Nice print of command-line options \n",
    "'''\n",
    "notify( (' ').join(args) )\n",
    "for x in args_dict:\n",
    "    log( '\\t%s: %s' % (x.upper(), args_dict[x]) )\n",
    "    \n",
    "\n",
    "'''\n",
    "Verify local archive\n",
    "'''\n",
    "if not os.path.exists( config.archive ):\n",
    "    log( 'Making new directory: [%s]' % config.archive )\n",
    "    \n",
    "    try:\n",
    "        os.makedirs( config.archive )\n",
    "    except Exception,e:\n",
    "        error('Cannot create archive folder [%s] %s:%s' % \\\n",
    "              ( config.archive, Exception,e))\n",
    "\n",
    "try:\n",
    "    os.stat( config.archive )\n",
    "except Exception,e:\n",
    "    error('Cannot create archive folder [%s] %s:%s' % \\\n",
    "          ( config.archive, Exception,e))\n",
    "    \n",
    "log( 'Working on archive: [%s]' % config.archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makePath( path, cache ):\n",
    "    '''\n",
    "    makePath:\n",
    "    \n",
    "    Traverse the dictionary structure and build full paths.\n",
    "    Since each key is a portion of the path until the last\n",
    "    key with a NULL value. That is the filename.\n",
    "    '''\n",
    "    \n",
    "    pathList = []\n",
    "    \n",
    "    for k,v in cache.iteritems():\n",
    "        \n",
    "        if not v:\n",
    "            pathList.append( '%s/%s' % (path,k) )\n",
    "        else:\n",
    "            pathList += makePath( '%s/%s' % (path,k), v )\n",
    "            \n",
    "    return pathList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsetFiles( fileList ):\n",
    "    '''\n",
    "    subsetFiles:\n",
    "    \n",
    "    From all files found filter the ones that\n",
    "    match the config.filter regex.\n",
    "    \n",
    "    '''\n",
    "    log( 'Make full paths of each file' )\n",
    "    \n",
    "    log( 'Total files [%s]' % len(fileList) )\n",
    "\n",
    "    if config.filter:\n",
    "        log( 'Make regex filter for files [%s]' % config.filter )\n",
    "        regex = re.compile( config.filter )\n",
    "\n",
    "        fileList = filter(regex.search, fileList)\n",
    "        log( 'Total files after subset[%s]' % len(fileList) )\n",
    "\n",
    "    log( 'Final file list' )\n",
    "    log( fileList ) \n",
    "    \n",
    "    return fileList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse( ftp ):\n",
    "    \"\"\"\n",
    "    traverse:\n",
    "    \n",
    "    return a recursive listing of an ftp server contents\n",
    "\n",
    "    listing is returned as a recursive dictionary, where each key\n",
    "    contains a contents of the subdirectory or None if it corresponds\n",
    "    to a file.\n",
    "    \"\"\"\n",
    "    level = {}\n",
    "    dirList = []\n",
    "    ftp.dir(dirList.append)\n",
    "    \n",
    "    for each in (path for path in dirList[1:] if path not in ('.', '..')):\n",
    "        #log( 'traverse: [%s]' % each )\n",
    "        name = each.strip().split(' ')[-1]\n",
    "        #'drwxrwxrwx  11 5000     5000         4096 Nov 20 23:54 201711'\n",
    "        \n",
    "        try:\n",
    "            ftp.cwd( name )\n",
    "            level[name] = traverse( ftp )\n",
    "            ftp.cwd( '..' )\n",
    "        except:\n",
    "            level[name] = None\n",
    "    return level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverseLocal( folder ):\n",
    "    '''\n",
    "    traverseLocal:\n",
    "    \n",
    "    return a recursive listing of a directory structure\n",
    "\n",
    "    listing is returned as a recursive dictionary, where each key\n",
    "    contains a contents of the subdirectory or None if it corresponds\n",
    "    to a file.\n",
    "    '''\n",
    "    level = {}\n",
    "    \n",
    "    dirList = []\n",
    "    \n",
    "    #log( 'Traverse Local Folder: [%s]' % folder )\n",
    "    \n",
    "    #cwd = os.getcwd()\n",
    "    #os.chdir( folder )\n",
    "    \n",
    "    #for each in (path for path in  os.listdir('.') if path not in ('.', '..')):\n",
    "    for each in (path for path in  os.listdir( folder ) if path not in ('.', '..')):\n",
    "        fullname = '%s/%s' % (folder, each)\n",
    "        #log( 'traverse: [%s]' % fullname )\n",
    "        \n",
    "        if os.path.isfile( fullname ):\n",
    "            level[each] = None\n",
    "        else:\n",
    "            level[each] = traverseLocal( fullname )\n",
    "\n",
    "    #os.chdir( cwd )\n",
    "    \n",
    "    return level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileDate( filename ):\n",
    "    '''\n",
    "    fileDate:\n",
    "    \n",
    "    Parse file name into file date object\n",
    "        # EXAMPLE:    KERG201711172100a.T00\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        m = re.search( r'^.*(\\d{4})(\\d{2})(\\d{2})(\\d{2})(\\d{2}).*$', filename)\n",
    "        #log( 'regex: %s/%s/%s %s:%s' % (m.group(1),m.group(2),m.group(3),m.group(4),m.group(5)) )\n",
    "        testdate = datetime( int(m.group(1)), int(m.group(2)), int(m.group(3)), int(m.group(4)), int(m.group(5)) )\n",
    "    except Exception, e:\n",
    "        log( '%s: %s' % (Exception,e) )\n",
    "        yr = int( filename[4:8] )\n",
    "        mt = int( filename[8:10] )\n",
    "        dy = int( filename[10:12] )\n",
    "        hr = int( filename[12:14] )\n",
    "        mn = int( filename[14:16] )\n",
    "        #log( 'simple: %s/%s/%s %s:%s' % (yr,mt,dy,hr,mn) )\n",
    "        testdate = datetime( yr, mt, dy, hr, mn )\n",
    "        \n",
    "    if testdate < datetime(2000, 1, 1) or datetime(2100, 1, 1)< testdate:\n",
    "        notify( '%s' % filename )\n",
    "        error( 'Date is not valid in filename!!!' )\n",
    "        \n",
    "    log( '\\tNew time: %s' % testdate )\n",
    "    \n",
    "    return testdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateLimit( conf ):\n",
    "    '''\n",
    "    dateLimit:\n",
    "    \n",
    "    Calculate date limit of files that we want to\n",
    "    download. Based on command-line flags.\n",
    "        - age limit: No more than X weeks or Y months\n",
    "        - date limit: Not older than day X\n",
    "    '''\n",
    "    \n",
    "    now = datetime.now()\n",
    "    \n",
    "    limit = datetime( 2000, 1, 1 )\n",
    "    \n",
    "    # maybe we have a timewindow\n",
    "    if conf.agelimit:\n",
    "        \n",
    "        log( 'Parse age limit of files [%s]' % conf.agelimit )\n",
    "        try:\n",
    "            m = re.search( r'^(\\d+)(\\w+)$', conf.agelimit)\n",
    "            digit = int( m.group(1) )\n",
    "            string = m.group(2)\n",
    "            log( 'Limit to %s %s' % (digit, string) )\n",
    "            \n",
    "            if re.match( r'month.?', string ):\n",
    "                m, y = (now.month+digit) % 12, now.year + ((now.month)+digit-1) // 12\n",
    "                if not m: m = 12\n",
    "                d = min(now.day, [31,\n",
    "                    29 if y%4==0 and not y%400==0 else 28,31,30,31,30,31,31,30,31,30,31][m-1])\n",
    "                limit = now.replace(day=d,month=m, year=y)\n",
    "            elif re.match( r'week.?', string ):\n",
    "                limit = now - timedelta( weeks=digit )\n",
    "            elif re.match( r'day.?', string ):\n",
    "                limit = now - timedelta( days=digit )\n",
    "            else:\n",
    "                error( 'Cannot parse age limit string: [%s]' % string)\n",
    "                \n",
    "        except Exception,e:\n",
    "            error( 'Problem parsing age limit %s %s' % (Exception, e) )\n",
    "            \n",
    "            \n",
    "    # maybe we have a date limit\n",
    "    if conf.datelimit:\n",
    "        \n",
    "        log( 'Parse date limit of files [%s]' % conf.datelimit )\n",
    "        dateparts = conf.datelimit.split('/')\n",
    "        \n",
    "        try:\n",
    "            log( 'date limit: %s/%s/%s' % (dateparts[0],dateparts[1],dateparts[2]) )\n",
    "            limit = datetime( int(dateparts[0]), int(dateparts[1]), int(dateparts[2]) )\n",
    "        except Exception,e:\n",
    "            error( 'Problem parsing date limit %s %s' % (Exception, e) )\n",
    "            \n",
    "    if limit > datetime( 2000, 1, 1 ):\n",
    "        log( 'Limit on age of files found to be: %s' % limit )\n",
    "    else:\n",
    "        log( 'No limit on age of files')\n",
    "        \n",
    "    return limit\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trashFile( filename ):\n",
    "    '''\n",
    "    trashFile:\n",
    "    \n",
    "    Move file to trash mode.\n",
    "    In case of partial download then move to the side and\n",
    "    append _trash_# for each extra version.\n",
    "    '''\n",
    "    notify( 'Move file to trash structure: %s' % filename )\n",
    "    \n",
    "    otherFiles = glob.glob( filename + '*' )\n",
    "    \n",
    "    if len(otherFiles):\n",
    "        notify( 'Found %s other files for it.' % len(otherFiles) )\n",
    "        for each in otherFiles:\n",
    "            notify( '\\t%s %s bytes' % (each,os.path.getsize(each)) )\n",
    "    else:\n",
    "        notify( 'No other trahs files for it.' )\n",
    "        \n",
    "    newName = filename + '_trash_' + str(len(otherFiles))\n",
    "    try:\n",
    "        os.rename( filename, newName )\n",
    "    except Exception,e:\n",
    "        error( 'Cannot move %s to %s trash structure: %s %s' % (filename, newName, Exception,e) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadFTP( ftp, remoteFile, localFile, delete=False, blocksize=8192 ):\n",
    "    '''\n",
    "    downloadFTP:\n",
    "    \n",
    "    Download file from FTP server.\n",
    "        - Verify if we have directory ready\n",
    "        - Download the file\n",
    "        - Verify final size of local file\n",
    "        - Move to \"trash\" mode if different size\n",
    "        - Remove remote if needed\n",
    "    '''\n",
    "    \n",
    "    (localDir, localName)= os.path.split(localFile)\n",
    "    success = False\n",
    "    totalFiles = 0\n",
    "    totalDeleted = 0\n",
    "    \n",
    "    # Verify local archive\n",
    "    log( '\\tOpen pointer to local file: %s' % localFile )\n",
    "    try:\n",
    "        if not os.path.isdir( localDir ):\n",
    "            os.makedirs( localDir )\n",
    "        fileObj = open(localFile, 'wb')\n",
    "    except Exception,e:\n",
    "        error( '\\tProblem creating new file: %s %s' % (Exception,e))\n",
    "        \n",
    "    # Download the file a chunk at a time using RETR\n",
    "    ftp.retrbinary('RETR ' + remoteFile, fileObj.write, blocksize)\n",
    "    \n",
    "    # Close the file\n",
    "    fileObj.close()\n",
    "    \n",
    "    fileSize = ftp.size( remoteFile )\n",
    "    log( '\\tFile size: %s bytes' % fileSize )\n",
    "    \n",
    "    localFileSize = os.path.getsize(localFile)\n",
    "    log( '\\tLocal File: %s bytes' % localFileSize )\n",
    "    \n",
    "    if localFileSize == fileSize:\n",
    "        log( '\\tSuccess in download of file.')\n",
    "        notify( 'Downloaded: %s' % localName )\n",
    "        success = True\n",
    "        totalFiles += 1\n",
    "    else:\n",
    "        notify( 'ERROR in download. Remove local file.')\n",
    "        notify( 'remote:[%s bytes] local:[%s bytes]' % (fileSize, localFileSize) )\n",
    "        try:\n",
    "            trashFile( localFile )\n",
    "        except Exception,e:\n",
    "            error( '\\tCannot remove partial local file: %s [%s:%s]' % \\\n",
    "                  (localFile, Exception, e) )\n",
    "\n",
    "    if delete:\n",
    "        notify( 'Delete remote file:%s' % remoteFile )\n",
    "        ftp.delete( remoteFile )\n",
    "        totalDeleted += 1\n",
    "            \n",
    "            \n",
    "    return {\n",
    "        'success': success,\n",
    "        'size':localFileSize,\n",
    "        'localDir':localDir,\n",
    "        'localName':localName,\n",
    "        'totalFiles':totalFiles,\n",
    "        'totalDeleted':totalDeleted,\n",
    "        'downloaded':fileSize\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syncFTP( conf ):\n",
    "    '''\n",
    "    syncFTP: Coordinate the download of the files:\n",
    "    \n",
    "    - Read the remote folder\n",
    "    - Read the local folder\n",
    "    - Compile list of missing files\n",
    "    - Connect to an FTP server and bring down files to the local directory\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        notify( 'Connect to %s' % conf.ftpServer )\n",
    "        ftpSite = FTP( conf.ftpServer )\n",
    "        \n",
    "        #if conf.verbose:\n",
    "        #    ftpSite.set_debuglevel( 1 )\n",
    "            \n",
    "        if conf.debug:\n",
    "            ftpSite.set_debuglevel( 2 )\n",
    "            \n",
    "    except:\n",
    "        error( 'Cannot find server %s' % conf.ftpServer )\n",
    "        \n",
    "    notify( 'Connecting...' )\n",
    "    if conf.user and conf.password:\n",
    "        log( 'login( %s, %s )' % (conf.user,conf.password) )\n",
    "        ftpSite.login(conf.user,conf.password)\n",
    "    else:\n",
    "        ftpSite.login()\n",
    "        \n",
    "    ftpSite.cwd( '/' )\n",
    "    \n",
    "    \n",
    "    notify( 'Read remote folder structure...' )\n",
    "    \n",
    "    try:\n",
    "        remoteFiles = subsetFiles( makePath( '', traverse( ftpSite ) ) )\n",
    "    except:\n",
    "        error( 'Remote directory listing ERROR - ' )\n",
    "    \n",
    "    localFiles = subsetFiles( makePath( '', traverseLocal( conf.archive ) ) )\n",
    "    \n",
    "    transferList = list(set(remoteFiles) - set(localFiles))\n",
    "    notify( 'Missing %s files' % len(transferList) )\n",
    "    \n",
    "    try:\n",
    "        filesMoved = 0\n",
    "        totalBytes = 0\n",
    "        totalFiles = []\n",
    "        totalMissed = []\n",
    "        dateFileLimit = dateLimit( conf ) \n",
    "        \n",
    "        for fl in sorted(transferList, reverse=False):\n",
    "            \n",
    "            fileDateObject = fileDate( fl )\n",
    "            log( 'File: %s Date: %s' % (fl, fileDateObject) )\n",
    "            \n",
    "            if fileDateObject < dateFileLimit:\n",
    "                log( '\\tFile too old. Skip.')\n",
    "                continue\n",
    "                \n",
    "            localFile =  os.path.abspath('%s/%s' % (conf.archive, fl) )\n",
    "            \n",
    "            if conf.maxAttempts:\n",
    "                otherFiles = glob.glob( localFile + '*' )\n",
    "                \n",
    "                if len(otherFiles) >= 1:\n",
    "                    log( '\\tAlready have %s attempts to this file' % len(otherFiles) )\n",
    "                    for each in otherFiles:\n",
    "                        modified = datetime.fromtimestamp(os.path.getmtime(each))\n",
    "                        log( '\\t%s %s bytes on %s' % (each,os.path.getsize(each),modified) )\n",
    "                \n",
    "                if len(otherFiles) >= conf.maxAttempts:\n",
    "                    notify( '\\tSkip. Max attempts on: %s' % len(otherFiles) )\n",
    "                    log( '\\t%s' % (otherFiles) )\n",
    "                    continue\n",
    "            \n",
    "            log( '\\tStart work on: %s' % fl )\n",
    "            \n",
    "            if conf.demo:\n",
    "                log( '\\tDEMO RUN. Skip' )\n",
    "                continue\n",
    "              \n",
    "            \n",
    "            results = downloadFTP( ftpSite, fl, localFile,\n",
    "                                  delete=conf.delete,\n",
    "                                  blocksize=conf.blocksize )\n",
    "            #{\n",
    "            #    'success': success,\n",
    "            #    'size':localFileSize,\n",
    "            #    'localDir':localDir,\n",
    "            #    'localName':localName,\n",
    "            #    'totalFiles':totalFiles,\n",
    "            #    'totalDeleted':totalDeleted,\n",
    "            #    'downloaded':fileSize\n",
    "            #}\n",
    "            \n",
    "            if results['success']:\n",
    "                totalFiles.append( results['localName'] )\n",
    "                filesMoved += results['totalFiles']\n",
    "            else:\n",
    "                totalMissed.append( results['localName'] )\n",
    "                \n",
    "            totalBytes += results['downloaded']\n",
    "            \n",
    "            if conf.maxFiles:\n",
    "                log( '\\t%s/%s max files allowed' % (filesMoved,conf.maxFiles) )\n",
    "                if filesMoved >= conf.maxFiles:\n",
    "                    notify( '\\tGot to limit on total files: %s' % conf.maxFiles )\n",
    "                    break\n",
    "                    \n",
    "            if conf.maxBytes:\n",
    "                log( '\\t%s/%s max bytes allowed' % (totalBytes,conf.maxBytes) )\n",
    "                if totalBytes >= conf.maxBytes:\n",
    "                    notify( '\\tGot to limit on total bytes: %s' % conf.maxBytes )\n",
    "                    break\n",
    "            \n",
    "        notify( 'Downloaded %s Files with %s bytes' %  (filesMoved, totalBytes) )\n",
    "        for each in totalFiles:\n",
    "            log( 'Downloaded: %s' % each )\n",
    "        \n",
    "        if len( totalMissed ):\n",
    "            notify( 'Error on %s files' %  totalMissed )\n",
    "            notify(  totalMissed )\n",
    "        else:\n",
    "            notify( 'No errors on any download.' )\n",
    "        \n",
    "    except Exception, e:\n",
    "        error( 'Download Error %s: %s' % ( Exception, e) )\n",
    "        \n",
    "    ftpSite.close() # Close FTP connection\n",
    "    ftpSite = None\n",
    "    \n",
    "    return len(totalMissed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/22/17 23:11:54.952402: Connect to 139.78.120.60\n",
      "11/22/17 23:11:55.167577: Connecting...\n",
      "11/22/17 23:11:55.543917: Read remote folder structure...\n",
      "11/22/17 23:12:12.530884: Missing 159 files\n",
      "11/22/17 23:12:17.815230: Downloaded: KERG201711200400a.T00\n",
      "11/22/17 23:12:23.112417: Downloaded: KERG201711200500a.T00\n",
      "11/22/17 23:12:27.557144: Downloaded: KERG201711200600a.T00\n",
      "11/22/17 23:12:31.594097: Downloaded: KERG201711200700a.T00\n",
      "11/22/17 23:12:36.409582: Downloaded: KERG201711200800a.T00\n",
      "11/22/17 23:12:41.137582: Downloaded: KERG201711200900a.T00\n",
      "11/22/17 23:12:41.137817: \tGot to limit on total files: 6\n",
      "11/22/17 23:12:41.137871: Downloaded 6 Files with 13630885 bytes\n",
      "11/22/17 23:12:41.137943: No errors on any download.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Start download of the data files\n",
    "'''\n",
    "log( 'Retreiving Files' )\n",
    "\n",
    "if 'ipykernel' in sys.modules:\n",
    "    # Run this if inside Jupyter Notebook\n",
    "    syncFTP(config)\n",
    "else:\n",
    "    sys.exit( syncFTP(config) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   # make files writeable by owner and group\n",
    "#   # chmod ug+w *\n",
    "#   echo 'converting .T00 files to .dat files'\n",
    "#   foreach f ($daily_raw/*.T00)\n",
    "#      runpkr00 -d $f\n",
    "#   end\n",
    "#   echo 'Converted .T00 files to .DAT files'\n",
    "#   \n",
    "#   \n",
    "#   # Making rinex files using teqc\n",
    "#   cd $daily_rinex\n",
    "#   foreach datfile ( $daily_raw/*.dat )\n",
    "#     set fname = `basename -s .dat $datfile`\n",
    "#     teqc ++err translate_${doy}.err -tr d $datfile > $fname.${yr}o \n",
    "#   end\n",
    "#   \n",
    "#   # qc data\n",
    "#   # get all 4 char site names from the list of files \n",
    "#   ls *.${yr}o | awk '{print substr($1,1,4)}' | sort | uniq > tmp_sitelist.txt\n",
    "#   foreach site (`cat tmp_sitelist.txt`)\n",
    "#     echo 'GPS DATA QC in progress'\n",
    "#     # teqc +qc *.${yr}o > $qcname.${yr}S\n",
    "#     teqc +qc $site*.${yr}o  > /dev/null\n",
    "#   end\n",
    "#   echo $daily_qc\n",
    "#   mv *.${yr}S $daily_qc\n",
    "#   mv translate_${doy}.err $daily_qc\n",
    "#   \n",
    "#   foreach rinex_file ( *.${yr}o )\n",
    "#     rnx2crx $rinex_file\n",
    "#     rm $rinex_file\n",
    "#   end\n",
    "#   compress *.${yr}d\n",
    "#   \n",
    "#   # Clean up \n",
    "#   rm tmp_sitelist.txt\n",
    "#   cd $daily_raw\n",
    "#   rm *.dat\n",
    "#   compress *.T00\n",
    "#   \n",
    "#   cd $current_dir\n",
    "#   \n",
    "#   echo \"get_gpsdata complete for $year $doy = $year-$month-$day\"\n",
    "#   # when using cron, may have to change the doy variable....depends on when cron job takes\n",
    "#   # place.\n",
    "#   # still need to find out about t02 to rinex....\n",
    "#   #  annnnnnd break..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
