.TH CODAR2ORB 1 "$Date: 2004/02/24 22:56:48 $"
.SH NAME
codar2orb \- retrieve CODAR data files and encapsulate on orb
.SH SYNOPSIS
.nf
\fBcodar2orb \fP[-v] [-V] [-p \fIpfname\fP] [-s \fIstatefile\fP] [-m \fImintime\fP]
                [-i \fI interval\fP] \fItrackingdb\fP \fIbasedir\fP \fIorbname\fP
.fi
.SH DESCRIPTION
\fBcodar2orb\fP periodically checks one or more local directory hierarchies
for CODAR (Coastal Ocean Dynamics Applications Radar) data files, 
encapsulating any new or modified files into 
orb packets. Each encapsulated file is put on the orbserver named on the 
command line (\fIorbname\fP). All directory hierarchies must be subdirectories of a 
given base-directory specified on the command line (\fIbasedir\fP).

Files that are processed are tracked in a Datascope relational database
in Codar0.3 format. The database name is given as the \fItrackingdb\fP argument 
on the command line. New files are added to the \fIradialfiles\fP or \fIvectorfiles\fP
table, as specified in the parameter file. Database records are updated when
modified files are found.

An optional statefile keeps track of the modification time for the latest 
file processed. Subsequent runs referring to the same statefile will process 
only files newer than that time-stamp (i.e. using the filesystem modification 
time, not the time value for the data).

.SH OPTIONS
.IP "-i interval_sec"
Introduce a delay of the specified number of seconds between each packet. 
This is useful when initially processing a multi-year accumulation of 
files, to avoid flooding an orbserver that has not been configured for the full 
historical data-volume. This parameter may specify a fractional number of 
seconds.

.IP "-m mintime"
This option specifies a minimum data time to consider. Files corresponding 
to data earlier than this will not be processed. The time may be specified 
as any string acceptable to the str2epoch(3) command. Quotes may be necessary 
around the time string to keep it from being interpreted as multiple arguments 
by the shell. 

.IP "-p pfname"
Use the specified parameter file instead of the default \fBcodar2orb\fP.pf

.IP "-s statefile"
Use the specified file to track the latest modification time
that has been handled in each directory hierarchy

.IP -v
Verbose output

.IP -V
Very verbose output

.SH PARAMETER FILE
.ft CW
.in 2c
The parameter file contains a table of subdirectories to monitor for 
interesting files. Each subdirectory to monitor is described by an array
with several components. The \fIsite\fP parameter gives the name of the 
radar station in question. The \fIformat\fP parameter specifies the 
format of the data file, which through the \fIformats\fP table gives the 
suffix for the orb-packet's sourcename and the version number for the packet.
The \fIglob\fP parameter specifies 
a filesystem glob to be used with the Unix find(1) command, which identifies
the files of interest. The \fItables\fP parameter gives the table of the 
tracking database which will be used to track the given set of files. 
The parameter \fImdyhms\fP gives a piece of perl code which, when evaluated 
within a perl script (i.e. with the perl \fIeval\fP command), produces 
an array with the month, day, year, hour, minute, and second numbers for the 
data block, respectively. Note the doubled escape (backslash) characters
for the perl regular expression, to prevent the backslash from being interpreted
by the parameter-file parser. The \fIprune\fP parameter lists an optional directory to 
prune during the search. This may be left blank if desired. 
.nf
prune UnsortedFiles 

subdirs &Tbl{
	&Arr{
		site		SDBP
		format		rcdrr1.0
		glob		RadsSDBP_*	
		mdyhms		(($dfile =~ /RadsSDBP_(\\\\d\\\\d)-(\\\\d\\\\d)-(\\\\d\\\\d)_(\\\\d\\\\d)(\\\\d\\\\d)/)[1,2,0,3,4],0)
		table		radialfiles
	}
	&Arr{
		site		SDBP	
		format		rcdrrhf1.0
		glob		RUVsSDBP_*
		mdyhms		(($dfile =~ /RUVsSDBP_(\\\\d\\\\d)-(\\\\d\\\\d)-(\\\\d\\\\d)_(\\\\d\\\\d)(\\\\d\\\\d)/)[1,2,0,3,4],0)
		table		radialfiles
	}
	&Arr{
		site		SDCI	
		format		rcdrr1.0
		glob		RadsSDCI_*	
		mdyhms		(($dfile =~ /RadsSDCI_(\\\\d\\\\d)-(\\\\d\\\\d)-(\\\\d\\\\d)_(\\\\d\\\\d)(\\\\d\\\\d)/)[1,2,0,3,4],0)
		table		radialfiles
	}
	&Arr{
		site		SDCI	
		format		rcdrrhf1.0
		glob		RUVsSDCI_*
		mdyhms		(($dfile =~ /RUVsSDCI_(\\\\d\\\\d)-(\\\\d\\\\d)-(\\\\d\\\\d)_(\\\\d\\\\d)(\\\\d\\\\d)/)[1,2,0,3,4],0)
		table		radialfiles
	}
	&Arr{
		site		SDPL	
		format		rcdrr1.0
		glob		RadsSDPL_*	
		mdyhms		(($dfile =~ /RadsSDPL_(\\\\d\\\\d)-(\\\\d\\\\d)-(\\\\d\\\\d)_(\\\\d\\\\d)(\\\\d\\\\d)/)[1,2,0,3,4],0)
		table		radialfiles
	}
	&Arr{
		site		SDPL	
		format		rcdrrhf1.0
		glob		RUVsSDPL_*
		mdyhms		(($dfile =~ /RUVsSDPL_(\\\\d\\\\d)-(\\\\d\\\\d)-(\\\\d\\\\d)_(\\\\d\\\\d)(\\\\d\\\\d)/)[1,2,0,3,4],0)
		table		radialfiles
	}
	&Arr{
		site		UABC	
		format		rcdrr1.0
		glob		RadsUABC_*	
		mdyhms		(($dfile =~ /RadsUABC_(\\\\d\\\\d)-(\\\\d\\\\d)-(\\\\d\\\\d)_(\\\\d\\\\d)(\\\\d\\\\d)/)[1,2,0,3,4],0)
		table		radialfiles
	}
	&Arr{
		site		UABC	
		format		rcdrrhf1.0
		glob		RUVsUABC_*
		mdyhms		(($dfile =~ /RUVsUABC_(\\\\d\\\\d)-(\\\\d\\\\d)-(\\\\d\\\\d)_(\\\\d\\\\d)(\\\\d\\\\d)/)[1,2,0,3,4],0)
		table		radialfiles
	}
	&Arr{
		site		SDLJ	
		format		rcdrvhf1.0
		glob		Tot_SDLJ_*.mat
		mdyhms		(($dfile =~ /Tot_SDLJ_(\\\\d\\\\d\\\\d\\\\d)(\\\\d\\\\d)(\\\\d\\\\d).(\\\\d\\\\d)(\\\\d\\\\d).mat/)[1,2,0,3,4],0)
		table		vectorfiles
	}
}

formats &Arr{
	rcdrr1.0	EXP/RCDRR	100
	rcdrrhf1.0	EXP/RCDRRHF	100
	rcdrvhf1.0	EXP/RCDRVHF	100
}
.fi
.in
.ft R
.SH EXAMPLE
.ft CW
.in 2c
.nf

.ne 5
%\fB codar2orb -m '1/24/04' -v codarstuff /angel0/CodarData/Data :\fP
Creating tracking-database codarstuff
Executing: find /angel0/CodarData/Data  -name 'RadsSDBP_*' -print
Processing RadsSDBP_04-01-24_0000, timestamped  1/24/2004   0:00:00.000
Processing RadsSDBP_04-01-24_0100, timestamped  1/24/2004   1:00:00.000
Processing RadsSDBP_04-01-24_0200, timestamped  1/24/2004   2:00:00.000
Processing RadsSDBP_04-01-24_0300, timestamped  1/24/2004   3:00:00.000
Processing RadsSDBP_04-01-24_0400, timestamped  1/24/2004   4:00:00.000
Processing RadsSDBP_04-01-24_0500, timestamped  1/24/2004   5:00:00.000
Processing RadsSDBP_04-01-24_0600, timestamped  1/24/2004   6:00:00.000
Executing: find /angel0/CodarData/Data  -name 'RUVsSDBP_*' -print
Processing RUVsSDBP_04-01-24_0000, timestamped  1/24/2004   0:00:00.000
Processing RUVsSDBP_04-01-24_0100, timestamped  1/24/2004   1:00:00.000
Processing RUVsSDBP_04-01-24_0200, timestamped  1/24/2004   2:00:00.000
Processing RUVsSDBP_04-01-24_0300, timestamped  1/24/2004   3:00:00.000
Processing RUVsSDBP_04-01-24_0400, timestamped  1/24/2004   4:00:00.000
Processing RUVsSDBP_04-01-24_0500, timestamped  1/24/2004   5:00:00.000
Processing RUVsSDBP_04-01-24_0600, timestamped  1/24/2004   6:00:00.000
Executing: find /angel0/CodarData/Data  -name 'RadsSDCI_*' -print
Executing: find /angel0/CodarData/Data  -name 'RUVsSDCI_*' -print
Executing: find /angel0/CodarData/Data  -name 'RadsSDPL_*' -print
Processing RadsSDPL_04-01-24_0000, timestamped  1/24/2004   0:00:00.000
Processing RadsSDPL_04-01-24_0100, timestamped  1/24/2004   1:00:00.000
Processing RadsSDPL_04-01-24_0200, timestamped  1/24/2004   2:00:00.000
Processing RadsSDPL_04-01-24_0300, timestamped  1/24/2004   3:00:00.000
Processing RadsSDPL_04-01-24_0400, timestamped  1/24/2004   4:00:00.000
Processing RadsSDPL_04-01-24_0500, timestamped  1/24/2004   5:00:00.000
Executing: find /angel0/CodarData/Data  -name 'RUVsSDPL_*' -print
Processing RUVsSDPL_04-01-24_0000, timestamped  1/24/2004   0:00:00.000
Processing RUVsSDPL_04-01-24_0100, timestamped  1/24/2004   1:00:00.000
Processing RUVsSDPL_04-01-24_0200, timestamped  1/24/2004   2:00:00.000
Processing RUVsSDPL_04-01-24_0300, timestamped  1/24/2004   3:00:00.000
Processing RUVsSDPL_04-01-24_0400, timestamped  1/24/2004   4:00:00.000
Processing RUVsSDPL_04-01-24_0500, timestamped  1/24/2004   5:00:00.000
Executing: find /angel0/CodarData/Data  -name 'RadsUABC_*' -print
Executing: find /angel0/CodarData/Data  -name 'RUVsUABC_*' -print
Executing: find /angel0/CodarData/Data  -name 'Tot_SDLJ_*.mat' -print
Processing Tot_SDLJ_20040124.0500.mat, timestamped  1/24/2004   5:00:00.000
Processing Tot_SDLJ_20040124.0000.mat, timestamped  1/24/2004   0:00:00.000
Processing Tot_SDLJ_20040124.0100.mat, timestamped  1/24/2004   1:00:00.000
Processing Tot_SDLJ_20040124.0200.mat, timestamped  1/24/2004   2:00:00.000
Processing Tot_SDLJ_20040124.0300.mat, timestamped  1/24/2004   3:00:00.000
Processing Tot_SDLJ_20040124.0400.mat, timestamped  1/24/2004   4:00:00.000
% 

In an Antelope real-time system, \fBcodar2orb\fP might be run under rtexec with the
following entry in rtexec.pf (five minutes past every half-hour in this example):

crontab &Arr{
\fBcodar2orb  UTC 5,35 * * * * codar2orb -s state/codar2orb db/codar /angel0/CodarData/Data $ORB\fP
}

.fi
.in
.ft R
.SH "SEE ALSO"
.nf
orb2codar(1), orb2orb(1), str2epoch(3), pf(5)
.fi
.SH "BUGS AND CAVEATS"
The state-file monitoring is timestamped at the beginning of each run. If a given
run of \fBcodar2orb\fP takes too long, files that are added or modified after the start
but before the end of the run might be (fairly harmlessly) processed 
again on the next run.

Only the state file is used to determine whether a file has been ingested already. 
The timestamp in the state file for each subdirectory is updated only after
the entire subdirectory has been processed. If a \fBcodar2orb\fP run is stopped in the 
middle of a run through a large subdirectory, all of the finished files 
will be repeated on the next run because the state file for that subdirectory 
hasn't been changed yet (this behavior is intentional, to mesh with behavior of 
the \fIfind\fP command). In principle this duplication could be avoided by 
checking each file against an established tracking database. However, this has 
been avoided at present to escape the overhead cost of such double-checking. 
[The trade-off made is that restarts after crashes use more resources than necessary, 
so large runs under normal conditions can take fewer resources].

The time-parsing for input files requires an entry in the parameter file which is 
essentially a piece of perl code. This code is eval'd against the name of the 
data-file to produce a timestamp for the data. This of course presumes the file-names 
contain sufficient information for the time stamp. Also, though this mechanism is 
extremely general and powerful, it does require the system operatore to be at least 
minimally familiar with parameter-files and perl. 

There are two relevant pieces of time information for each file, which could be 
confusing. One is the modification time of the file on the filesystem; the other 
is the time value for the block of data. The latter is used with the -m option and 
in the database and orb packet timestamps. The former is used in the statefile
and for tracking of which files need updating. 

Given sufficient bandwidth, entire historical archives of CODAR data can be 
transferred as quickly as they can be loaded onto the orbserver. As one reduces 
the bandwidth in relation to the size of the historical archive, however, the size 
of the orbserver buffer becomes important: the orbserver buffer must be sufficiently 
large to meet the difference between outbound bandwidth and historical archive size. 
This may not always be desirable for running systems: most systems will probably want 
to set these ratios appropriate for the rate of the near-real-time data influx, not
for historical archive transmission. To prevent data-loss from this configuration 
choice, the -i option is used during historical archive transfer to throttle the 
rate of data loading onto the orb, to match the orb-buffer-size/outbound-bandwidth 
ratio configured for the real-time system.
.SH AUTHOR
.nf
Kent Lindquist
Lindquist Consulting
.fi
.\" $Id: codar2orb.1,v 1.9 2004/02/24 22:56:48 rt Exp $
